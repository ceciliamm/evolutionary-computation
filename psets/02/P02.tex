\documentclass[10pt,letterpaper]{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish,es-nodecimaldot]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathtools}

\usepackage{multicol}

\usepackage{enumitem}

\newcommand{\ihat}{\hat{\textbf{\i}}}
\newcommand{\jhat}{\hat{\textbf{\j}}}
\newcommand{\uhat}{\hat{\textbf{u}}}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}


\begin{document}

\begin{titlepage}
    \centering

    {\scshape\LARGE Universidad Nacional Autónoma de México \par}

    \vspace{1cm}
    {\scshape\Large Facultad de Ciencias\par}
    \vspace{1.5cm}

    \begin{center}
        \includegraphics[scale=.1]{../../assets/img/logo.png}
    \end{center}

    \vspace{.8 cm}

    {\LARGE Tarea 02: \par}
    {\huge\bfseries Convexidad, vecindarios, búsqueda local: Hill Climbing y Búsqueda Tabú \par}

    \vspace{0.5cm}
    \large{\itshape{Pablo A. Trinidad Paz}} \small{ - 419004279}

    \vfill

    Trabajo presentado como parte del curso de
    \textbf{Cómputo Evolutivo}
    impartido por el profesor \textbf{Mario Iván Jaen Márquez}. \par
    \vspace{0.5cm}
    Fecha de entrega: \textbf{22 de Febrero de 2019}.
\end{titlepage}

\section{Teoría}
    \begin{enumerate}
        \item Sean $f_2, f_2: \mathbb{R} \rightarrow \mathbb{R}$ dadas por
            \begin{equation*} \begin{split} \begin{aligned}
                f_1(x) &= x^2 - 2ex + e^2 - 2, \\
                f_2(x) &= x^6 - 6ex^5 + 15e^2x^4 - 20e^3x^3 + 15e^4x^2 - 6e^5x + e^6 - 6 \\
            \end{aligned} \end{split} \end{equation*} \\

            \begin{enumerate}
                \item Demuestre que $f_1$ y $f_2$ son funciones convexas \\

                    \textbf{Solución:}

                    Una función $f$ es convexa si se cumple que:
                    \begin{equation*} \begin{split} \begin{gathered}
                        \forall x, y \in Dom(f)  \text{ y } \forall a \in [0, 1] \\
                        f(ax + (1-a)y) \leq af(x) + (1 - a)f(y).
                    \end{gathered} \end{split} \end{equation*}
                    Además, se cumple que si la función es doblemente derivable
                    (y de una sola variable) es convexa en un intervalo sí y solo sí
                    su segunda derivada no es negativa.

                    Para $f_1(x)$:
                    \begin{equation*} \begin{split} \begin{gathered}
                        f_1'(x) = 2x - 2e \\
                        f_1''(x) = 2 \\
                        \Rightarrow f_1''(x) > 0 \\
                        \therefore \; f_1 \text{ es convexa} \quad \blacksquare
                    \end{gathered} \end{split} \end{equation*}

                    Para $f_2(x)$:
                    \begin{equation*} \begin{split} \begin{gathered}
                        f_2'(x) =  6 x^5  - 30 e x^4  + 60 e^2 x^3  - 60 e^3 x^2 + 30 e^4 x - 6 e^5  \\
                        f_2''(x) = 30 x^4 - 120 e x^3 + 180 e^2 x^2 - 120 e^3 x  + 30 e^4 \\
                        f_2''(x) = 30(e - x)^4 \\
                        \Rightarrow f_2''(x) > 0 \\
                        \therefore \; f_2 \text{ es convexa} \quad \blacksquare
                    \end{gathered} \end{split} \end{equation*}

                \item Utilice el algoritmo del descenso por gradiente implementado
                para minimizarlas. Use $x_0 = 0$ como punto inicial y $\alpha$
                arbitrario. ¿Qué valores de $\alpha$ hacen más eficiente el algoritmo
                para cada función? \\

                    \textbf{Solución:} \\
                    Para responder a la pregunta anterior se corrió el
                    descenso por gradiente con múltiples valores de $\alpha$
                    y se determinó que el valor de $\alpha$ más eficiente sería
                    aquel que lograra encontrar un óptimo en el menor número
                    de iteraciones. Para saber si el valor óptimo obtenido
                    a partir de dicha $\alpha$ era aceptable, se calculó la
                    desviación estándar, promedio y media de los resultados
                    de cada prueba. \\

                    Para ambas funciones, el gradiente corrió bajo los
                    siguientes parámetros:

                        \begin{itemize}
                            \item Precisión: $1 \times 10^{-8}$
                            \item Número máximo de iteraciones: $10^{10}$
                        \end{itemize}

                    \clearpage

                    \textbf{Resultados de $f_1$}: \\

                    \begin{center}
                        Valores de $\alpha$ para la función $f_1$ \\
                        \begin{tabular}{c|r|l} 
                            \hline
                            \multicolumn{1}{|c|}
                            {$\alpha$} & \textbf{Número de iteraciones} & \multicolumn{1}{l|}{\textbf{Valor mínimo}}  \\ 
                            \hline
                            0.000005    &    790773    &    2.71728184 \\
                            0.00001    &    430042    &    2.71778184 \\
                            0.00005    &    102100    &    2.71818185 \\
                            0.0001    &    54513    &    2.71823184 \\
                            0.0005    &    12508    &    2.71827184 \\
                            0.001    &    6598    &    2.71827684 \\
                            0.005    &    1476    &    2.71828085 \\
                            0.01    &    769    &    2.71828134 \\
                            0.05    &    164    &    2.71828174 \\
                            0.1    &    81    &    2.71828179 \\
                            0.5    &    2    &    2.71828183 \\
                        \end{tabular}
                    \end{center}

                    \begin{multicols}{2}
                        \begin{center}
                            \includegraphics[scale=.4]{assets/theory/1-a/f1-performance.png}
                        \end{center}
                        \begin{center}
                            \includegraphics[scale=.5]{assets/theory/1-a/f1-dist.png}
                        \end{center}
                    \end{multicols}

                    Con una desviación estándar $\sigma \approx 0.000303$,
                    promedio $\mu \approx 2.7181303273$ y media $\approx 2.7182768400$
                    se puede concluir de forma segura que el valor óptimo de $\alpha$ para
                    $f_1$ es \textbf{0.5} y que el mínimo se encuentra en
                    $x=2.718281828459045$.

                    \begin{center}
                        \includegraphics[scale=.6]{assets/theory/1-a/f1-minimum.png}
                    \end{center}

                    \clearpage

                    \textbf{Resultados de $f_2$}: \\
                    \begin{center}
                    Valores de $\alpha$ para la función $f_2$ \\
                    \begin{tabular}{c|r|l} 
                        \hline
                        \multicolumn{1}{|c|}
                        {$\alpha$} & \textbf{Número de iteraciones} & \multicolumn{1}{l|}{\textbf{Valor mínimo}}  \\ 
                        \hline
                            5e-06    &    5266300    &    2.45496429845281 \\
                            1e-05    &    4691757    &    2.4836925848909828 \\
                            5e-05    &    3587912    &    2.538885692619941 \\
                            0.0001    &   3196467    &    2.5584580445544773 \\
                            0.0005    &   2444410    &    2.59606066860143 \\
                            0.001    &    2163480    &    2.60939515596596 \\

                        \end{tabular}
                    \end{center}

                    \begin{multicols}{2}
                        \begin{center}
                            \includegraphics[scale=.45]{assets/theory/1-a/f2-performance.png}
                        \end{center}
                        \begin{center}
                            \includegraphics[scale=.45]{assets/theory/1-a/f2-dist.png}
                        \end{center}
                    \end{multicols}

                    Con una desviación estándar $\sigma \approx 0.0558$,
                    promedio $\mu \approx 2.5402427408$ y media $\approx 2.5486718686$
                    Se puede utilizer \textbf{el valor más óptimo de} $\alpha = 0.001$ y
                    su mínimo hallado $x=2.60939515596596$ ya que se encuentra dentro de
                    $[\sigma - \mu, \sigma + \mu]$.

                    \begin{center}
                        \includegraphics[scale=.6]{assets/theory/1-a/f2-minimum.png}
                    \end{center}

                    \clearpage

            \end{enumerate}
    \end{enumerate}

\section{Práctica}

\end{document}
